import nltk
import re
import string
import random
import pandas as pd
import swifter
from textblob import Word, TextBlob
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer
from nltk.stem.porter import PorterStemmer
from nltk.tokenize import word_tokenize

stopword = nltk.corpus.stopwords.words('english')
ps = nltk.PorterStemmer()
wn = nltk.WordNetLemmatizer()

def full_clean(text):
    text = "".join([char for char in text if char not in string.punctuation])#discard all punctuations
    text = re.split('\W+', text) #tokenizing
    text = [word for word in text if word not in stopword]#remove all stopwords
    text = [ps.stem(word) for word in text] #stemming
    text = [wn.lemmatize(word) for word in text] #lemmatizing
    return text

def formatter(x):
    text = re.sub(r'\[[0-9]*\]', ' ', x)
    text = re.sub(r'\s+', ' ', text)
    text = "".join([char for char in text if char not in string.punctuation])#discard all punctuations
    text = re.sub('[^a-zA-Z]', ' ', text) # formatting
    return text
    
def word_freq(text):
    word_frequencies = {}
    for word in text:
        if word not in stopword:
            if word not in word_frequencies.keys():
                word_frequencies[word] = 1
            else:
                word_frequencies[word] += 1
    return word_frequencies

#removing index duplicates
def remove_duplicate(x):
    return list(dict.fromkeys(x))

def lemmatizer(text):
    text = re.sub(r'\[[0-9]*\]', ' ', text)
    text = re.sub(r'\s+', ' ', text)
    text = "".join([char for char in text if char not in string.punctuation])#discard all punctuations
    text = re.sub('[^a-zA-Z]', ' ', text) #formatting
    text = re.split('\W+', text) #tokenizing
    text = [word for word in text if word not in stopword]#remove all stopwords
    text = [ps.stem(word) for word in text] #stemming
    text = [wn.lemmatize(word) for word in text] #lemmatizing
    return text

def text_cleaner(x):
    summary = re.sub('[^a-zA-Z]', ' ',x)  
    summary = summary.lower()          
    return summary

def tagger(x):
    blob = TextBlob(x)
    nouns = list()
    for word, tag in blob.tags:
        if tag in[ 'NN', 'NNP','NNS','NNPS']:
            nouns.append(word)
    return nouns

